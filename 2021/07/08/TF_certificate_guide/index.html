<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Tensorflow基础 | 野生芦苇</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="tf证书主要考察四个方面的内容">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow基础">
<meta property="og:url" content="http://github.com/jinlongli2016/2021/07/08/TF_certificate_guide/index.html">
<meta property="og:site_name" content="野生芦苇">
<meta property="og:description" content="tf证书主要考察四个方面的内容">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-07-08T02:14:01.000Z">
<meta property="article:modified_time" content="2021-07-18T07:25:46.632Z">
<meta property="article:author" content="李金龙">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="https://shang.qq.com/wpa/qunwpa?idkey=b1f60f79b3ca3529de11e4d2eb36924a35f57ad3419b3a7563bbaad8043ba008" title="野生芦苇" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">野生芦苇</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">李金龙的随记</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/archives">主页</a>
        
          <a class="main-nav-link" href="/categories/Python">Python</a>
        
          <a class="main-nav-link" href="/categories/%E7%BC%96%E7%A8%8B">编程</a>
        
          <a class="main-nav-link" href="/categories/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E6%8A%80%E5%B7%A7%E4%B8%8E%E5%88%86%E6%9E%90/">算法设计</a>
        
          <a class="main-nav-link" href="/archives">历史文章</a>
        
          <a class="main-nav-link" href="/about/me">个人简历</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="https://shang.qq.com/wpa/qunwpa?idkey=b1f60f79b3ca3529de11e4d2eb36924a35f57ad3419b3a7563bbaad8043ba008" target="_blank" rel="noopener" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://github.com/jinlongli2016"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-TF_certificate_guide" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/07/08/TF_certificate_guide/" class="article-date">
  <time datetime="2021-07-08T02:14:01.000Z" itemprop="datePublished">2021-07-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a>►<a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>►<a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tensorflow/">tensorflow</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Tensorflow基础
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
      
<!-- Table of Contents -->



        <p>tf证书主要考察四个方面的内容</p>
<a id="more"></a>



<h1 id="1-Build-and-train-neural-network-models-using-TensorFlow-2-x"><a href="#1-Build-and-train-neural-network-models-using-TensorFlow-2-x" class="headerlink" title="(1) Build and train neural network models using TensorFlow 2.x"></a>(1) Build and train neural network models using TensorFlow 2.x</h1><p>You need to understand the foundational principles of machine learning (ML) and deep learning (DL) using TensorFlow 2.x. You need to know how to:<br>Use TensorFlow 2.x. </p>
<ul>
<li>Build, compile and train machine learning (ML)  models using TensorFlow. </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># for demonstration</span></span><br><span class="line">modl = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">                          padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line">    tf.keras.layers.GlobalAveragePooling(),</span><br><span class="line">    </span><br><span class="line">    tf.keras.layers.Dense(nb_classes, activation=<span class="string">'sigmod(if binary)/softmax(multiclass)'</span>)</span><br><span class="line">])</span><br><span class="line">model.compile(loss=<span class="string">'binary_corssentropy/categorical_crossentropy'</span>,</span><br><span class="line">             optimizer=<span class="string">'rmpsprop'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br><span class="line">model.fit(data)</span><br><span class="line">model.fit(xs, ys)</span><br></pre></td></tr></table></figure>

<ol>
<li>除序列模型以外，有其他较典型的模型吗？</li>
</ol>
<ul>
<li><p>Preprocess data to get it ready for use in a model. </p>
<ol>
<li>数据的维度</li>
<li>归一化</li>
<li>训练数据和测试数据的一致性</li>
</ol>
</li>
<li><p>Use models to predict results. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.predict(ds)</span><br><span class="line">model.predict(xs)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Build sequential models with multiple layers. </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1: add all layers at a time</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">                          padding=<span class="string">'same'</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line">    tf.keras.layers.GlobalAveragePooling(),</span><br><span class="line">    </span><br><span class="line">    tf.keras.layers.Dense(nb_classes, activation=<span class="string">'sigmod(if binary)/softmax(multiclass)'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2: 逐个增加序列模型的每一层</span></span><br><span class="line">model = tf.keras.models.Sequential()</span><br><span class="line">model.add(tf.keras.layers.GlobalAveragePooling())</span><br></pre></td></tr></table></figure>



<ul>
<li><p>Build and train models for binary classification. </p>
</li>
<li><p>Build and train models for multi-class categorization. </p>
</li>
<li><p>Plot loss and accuracy of a trained model. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hist = history.history <span class="comment"># dict</span></span><br><span class="line">loss, acc = hist[<span class="string">'loss'</span>], hist[<span class="string">'accuracy'</span>]</span><br><span class="line"></span><br><span class="line">epochs = list(range(len(loss)))</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, color=<span class="string">'b'</span>)</span><br><span class="line">plt.plot(epochs, acc, color=<span class="string">'r'</span>)</span><br><span class="line">plt.legend([<span class="string">'loss'</span>, <span class="string">'accuracy'</span>])</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>Identify strategies to prevent overfitting, including augmentation and dropout. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 防止过拟合策略：1. dropout 2. augmentation 3. batch normalization</span></span><br><span class="line"><span class="comment"># 1. dropout</span></span><br><span class="line">tf.layers.Dropout(rate)</span><br><span class="line"><span class="comment"># 2. augmentation</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">train_datagen = ImageGenerator.rescale(</span><br><span class="line">    rescale = <span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">20</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>)</span><br><span class="line">train_datagen.flow_from_directory(</span><br><span class="line">	dir,</span><br><span class="line">	target_size=(<span class="number">150</span>,<span class="number">150</span>),</span><br><span class="line">	batch_size=<span class="number">10</span>,</span><br><span class="line">	class_mode=<span class="string">'binary'</span>)</span><br><span class="line"><span class="comment"># 3 BN</span></span><br><span class="line">tf.keras.layers.BatchNormalization()</span><br></pre></td></tr></table></figure>

<ol>
<li><p><code>Dropout</code>: set inputs to zero at a rate of <code>rate</code>, then outputs are scaled 1/(1 - rate)，输入的和不变</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.random.set_seed(<span class="number">0</span>)</span><br><span class="line">dropout_layer = tf.keras.layers.Dropout(<span class="number">.2</span>, input_shape=(<span class="number">2</span>,))</span><br><span class="line">data = np.arange(<span class="number">10</span>).reshape(<span class="number">5</span>, <span class="number">2</span>).astype(np.float32)</span><br><span class="line">print(data)</span><br><span class="line"></span><br><span class="line">outputs = dropout_layer(data, training=<span class="literal">True</span>)</span><br><span class="line">print(outputs)</span><br></pre></td></tr></table></figure>

<p>只在训练时生效. <code>layer(training=True)</code> </p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization" target="_blank" rel="noopener">BatchNormalization</a> </p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># layter.trainable &#x3D; False vs inference mode?</span><br><span class="line"># 前者的意思是内部的状态不改变；后者的意思是网络运行在推理阶段。</span><br><span class="line"># BN层在训练时，trainable&#x3D;False 的表示mean和var采用当前batch的mean和var</span><br><span class="line"># inference则表明采用BN层自己的 滑动平均和滑动方差</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>Use pretrained models (transfer learning). </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load inception_v3</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications.inception_v3 <span class="keyword">import</span> InceptionV3</span><br><span class="line"></span><br><span class="line">pre_traine_model = InceptionV3(=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">                              include_top= <span class="literal">False</span>, <span class="comment"># include last dense layer?</span></span><br><span class="line">                              weights=<span class="literal">None</span>) <span class="comment"># where weights</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Extract features from pre-trained models. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#for layer in pre_trained_model.layers:</span></span><br><span class="line"><span class="comment">#    layer.trainable = False</span></span><br><span class="line">extracted_features = model(inputs)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Ensure that inputs to a model are in the correct shape. </p>
<ul>
<li>模型的第一层传入<code>input_shape</code>参数</li>
</ul>
</li>
<li><p>Ensure that you can match test data to the input shape of a neural network. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* Ensure you can match output data of a neural network to specified input shape <span class="keyword">for</span> test data. </span><br><span class="line"></span><br><span class="line">* Understand batch loading of data. </span><br><span class="line"></span><br><span class="line">  ```python</span><br><span class="line">  model.fit(xs, ys, batch_size=<span class="number">32</span>)</span><br><span class="line">  </span><br><span class="line">  modelf.fit(Dataset)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Use callbacks to trigger the end of training cycles. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCallbak</span><span class="params">(tf.keras.callbacks.Callback)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span><span class="params">(self, epoch, logs=&#123;&#125;)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> logs.get(<span class="string">'acc'</span>) &gt; DESIRED_ACCURACY:</span><br><span class="line">            print(<span class="string">"\n Reached desired accuracy"</span>)</span><br><span class="line">            self.model.stop_training = <span class="literal">True</span></span><br><span class="line">model.fit(callbacks = [MyCallback()])</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li>Use datasets from different sources. </li>
</ul>
<ul>
<li><p>Use datasets in different formats, including json and csv. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv, json, zipfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'csv.csv'</span>, mode=<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    reader = csv.reader(f, delimiter=<span class="string">','</span>)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">        <span class="comment"># process row</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'json.json'</span>, mode=<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    datastore = json.load(f)</span><br><span class="line">    </span><br><span class="line">zip_ref = zipfile.ZipFile(<span class="string">'zip.zip'</span>, <span class="string">'r'</span>)</span><br><span class="line">zip_ref.extractall(<span class="string">"tmp/training"</span>)</span><br><span class="line">zip_ref.close()</span><br></pre></td></tr></table></figure>
</li>
<li><p>Use datasets from tf.data.datasets. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(dataset)</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h1 id="2-Image-classification"><a href="#2-Image-classification" class="headerlink" title="(2)  Image classification"></a>(2)  Image classification</h1><p>You need to understand how to build image recognition and object detection models  with deep neural networks and convolutional neural networks using TensorFlow 2.x. You need to know how to: </p>
<ul>
<li><p>Define Convolutional neural networks with Conv2D and pooling layers. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">16</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">150</span>,<span class="number">150</span>,<span class="number">3</span>)),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>), <span class="comment"># 保留特征性东西而不关注位置；降维；</span></span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=RMSprop(lr=<span class="number">0.001</span>), loss=<span class="string">'binary_crossentropy'</span>, metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
</li>
<li><p>Build and train models to process real-world image datasets. </p>
</li>
<li><p>Understand how to use convolutions to improve your neural network. </p>
<ul>
<li>problem: 过拟合、欠拟合；数据情况；</li>
<li>查看数据关系情况：时序、图像、音频</li>
</ul>
</li>
</ul>
<ul>
<li><p>Use real-world images in different shapes and sizes.. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.preprocess.image_dataset_from_directory(</span><br><span class="line">    data_dir, validation_slit=<span class="number">0.2</span>, subset=<span class="string">"validation"</span>, seed=<span class="number">1123</span>, image_size=(h, w), batch_size=batch_size</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 从一个包含图片的文件夹创建一个dataset</span></span><br><span class="line"><span class="comment">#main_directory/</span></span><br><span class="line"><span class="comment">#...class_a/</span></span><br><span class="line"><span class="comment">#......a_image_1.jpg</span></span><br><span class="line"><span class="comment">#......a_image_2.jpg</span></span><br><span class="line"><span class="comment">#...class_b/</span></span><br><span class="line"><span class="comment">#......b_image_1.jpg</span></span><br><span class="line"><span class="comment">#......b_image_2.jpg</span></span><br></pre></td></tr></table></figure>





</li>
</ul>
<ul>
<li><p>Use image augmentation to prevent overfitting.  </p>
<p>旋转、翻转、缩放、高度/宽度偏移、伸缩(rescale)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># layers.experimental.preprocessing.</span></span><br><span class="line">data_augmentatoin = keras.Sequential([</span><br><span class="line">    layers.experimental.preprocessing.RandomFlip(<span class="string">"horizontal"</span>, input_shape=(h, w, <span class="number">3</span>)),</span><br><span class="line">    layers.experimental.preprocessing.RandomRotation(<span class="number">0.1</span>),</span><br><span class="line">    layers.experimental.preprocessing..RandomZoom(<span class="number">0.1</span>),</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 1. 可以作为网络层加入模型中 2. 可以不加入网络</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ImageDataGenerator</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">train_datagen = ImageGenerator(</span><br><span class="line">    rescale = <span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">20</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>) <span class="comment"># 图像生成时所做的变换</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Use <code>ImageDataGenerator</code>. </p>
<p>生成图像数据的批同时支持实时的数据扩增</p>
</li>
<li><p>Understand how ImageDataGenerator labels images based on the directory structure. </p>
<ul>
<li><p><code>ImageDataGenerator .flow_from_directory</code></p>
<p><code>data/train/dogs/xxx.jpg and data/validation/dogs/xxx.jpg</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.preprocessing.image.ImageGenerator(). \</span><br><span class="line">	flow_from_directory(dir, target_size=(<span class="number">32</span>, <span class="number">32</span>), color_mode=<span class="string">'rgb'</span>,class_mode=<span class="string">'binary'</span>)</span><br></pre></td></tr></table></figure>



</li>
</ul>
</li>
</ul>
<h1 id="3-Natural-language-processing-NLP"><a href="#3-Natural-language-processing-NLP" class="headerlink" title="(3)  Natural language processing (NLP)"></a>(3)  Natural language processing (NLP)</h1><p>You need to understand how to use neural networks to solve natural language processing problems using TensorFlow. You need to know how to: </p>
<ul>
<li><p>Build natural language processing systems using TensorFlow. </p>
</li>
<li><p>Prepare text to use in TensorFlow models. </p>
<ul>
<li>分词、文本变数字编码序列<ul>
<li>标准化样本：小写、移除标点符号</li>
<li>分割每个样本为substrings(words)</li>
<li>重新组合为token （常间的ngrams）</li>
<li>token -&gt; 索引（整数）</li>
<li>利用上式，将每个样本转换为索引序列。（可能为int的序列，或者为向量的序列）</li>
</ul>
</li>
<li>数字序列可以用作 词嵌入层 的输入</li>
</ul>
</li>
<li><p>Build models that  identify the category of a piece of text using binary categorization </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model = tf.kears.models.Sequential([</span><br><span class="line">    tf.keras.layers.word_embedding(</span><br><span class="line">    	voc_size, embed_size),</span><br><span class="line">    tf.keras.layers.LSTM(<span class="number">64</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>Build models that identify the category of a piece of text using multi-class categorization </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = tf.kears.models.Sequential([</span><br><span class="line">    tf.keras.layers.word_embedding(</span><br><span class="line">    	voc_size, embed_size),</span><br><span class="line">    tf.keras.layers.LSTM(<span class="number">64</span>),</span><br><span class="line">    tf.keras.layers.Dense(nb_classes, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line">model.compile(loss=<span class="string">'multiclass_crossentropy'</span>,</span><br><span class="line">             optimizer=<span class="string">'rmsprop'</span>,</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>Use word embeddings in your TensorFlow model. </p>
</li>
<li><p>Use LSTMs in your model to classify text for either binary or multi-class categorization. </p>
</li>
<li><p>Add RNN and GRU layers to your model. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = tf.kears.models.Sequential([</span><br><span class="line">    tf.keras.layers.word_embedding(</span><br><span class="line">    	voc_size, embed_size),</span><br><span class="line">    tf.keras.layers.RNN(<span class="number">64</span>),</span><br><span class="line">    tf.keras.layers.GRU(<span class="number">64</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
</li>
<li><p>Use RNNS, LSTMs, GRUs and CNNs in models that work with text. </p>
</li>
<li><p>Train LSTMs on existing text to generate text (such as songs and poetry) </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># given a sequences of text, generate following 100 word</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将过去的所有文字输入模型预测下一个word # tokenizer: 分词器</span></span><br><span class="line">seqs = []</span><br><span class="line">tokenizer.texts_to_sequences(texts)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_words</span><span class="params">(text, nb_words)</span>:</span></span><br><span class="line">    seq = tokenizer.texts_to_sequences(text)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(nb_words):</span><br><span class="line">        word_idx = model.predict_class(seq)</span><br><span class="line">        seq += word_idx,</span><br><span class="line">    <span class="comment"># convert seq to word</span></span><br><span class="line">   	words = []</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> seq:</span><br><span class="line">    	word = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> i,w <span class="keyword">in</span> tokenizer.word_index.items():</span><br><span class="line">            <span class="keyword">if</span> i == s:</span><br><span class="line">                word = w</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">         words += word,</span><br><span class="line">    <span class="keyword">return</span> words</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h1 id="4-Time-series-sequences-and-predictions"><a href="#4-Time-series-sequences-and-predictions" class="headerlink" title="(4) Time series, sequences and predictions"></a>(4) Time series, sequences and predictions</h1><p>You need to understand how to solve time series and forecasting problems in TensorFlow. You need to know how to: </p>
<ul>
<li><p>Train, tune and use time series, sequence and prediction models. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 时序数据一维度卷积时候padding要注意，使用'casual'的方式在seq的前部进行padding；以免对last part的信号产生干扰!</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Conv1D(filters=<span class="number">64</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>,  </span><br><span class="line">                         padding=<span class="string">'causal'</span>,</span><br><span class="line">                         activation=<span class="string">'relu'</span>,</span><br><span class="line">                         input_shape=(<span class="literal">None</span>,<span class="number">1</span>)),</span><br><span class="line">  tf.keras.layers.LSTM(<span class="number">64</span>, return_sequences=<span class="literal">True</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: x * <span class="number">100</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>Prepare data for time series learning. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sequens to training data</span></span><br><span class="line"></span><br><span class="line">series = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>] <span class="comment"># very long sequences</span></span><br><span class="line">window_size = <span class="number">30</span> <span class="comment"># 从时序数据中根据过去的30个点预测接下来的一个点</span></span><br><span class="line"></span><br><span class="line">ds = tf.data.Dataset.from_tensor_slices(series)</span><br><span class="line">ds = ds.window(size=window_size+<span class="number">1</span>, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ds = ds.flat_map(<span class="keyword">lambda</span> x: x.batch(window_size+<span class="number">1</span>) )</span><br><span class="line">ds = ds.map(<span class="keyword">lambda</span> x: (x[:<span class="number">-1</span>], x[<span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line">ds.shuffle(<span class="number">10</span>).map(<span class="keyword">lambda</span> x, y: (</span><br><span class="line">	tf.expand_dims(x, axis=<span class="number">-1</span>), tf.expand_dims(y, axis=<span class="number">-1</span>))</span><br><span class="line">                  ).batch(<span class="number">128</span>).prefetch(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># ds yields dataset of batch size 128 each iteration</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Understand Mean Average Error (MAE) and how it can be used to evaluate accuracy of sequence models. </p>
<p><code>err = abs(true - pred)</code></p>
<p>评估预测的值与真实数据的出入(deviation)</p>
</li>
</ul>
<ul>
<li><p>Use RNNs and CNNs for time series, sequence and forecasting models. </p>
<p>在温度时序预测中，数据的size为 <code>(B, time_steps, 1)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CNNs</span></span><br><span class="line">tf.keras.layers.Conv1D(filter, ks, strides, padding)</span><br><span class="line"></span><br><span class="line">tf.keras.layers.RNN(units=<span class="number">64</span>) <span class="comment"># LSTM/GRU  or with Bidirectional</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Identify when to use trailing versus centred windows. </p>
<p><a href="https://ww2.mathworks.cn/matlabcentral/answers/392300-what-is-meant-by-centered-moving-average-is-it-different-from-moving-average" target="_blank" rel="noopener">trailing versus centred windows</a></p>
</li>
<li><p>Use TensorFlow for forecasting. </p>
</li>
<li><p>Prepare features and labels. </p>
</li>
<li><p>Identify and compensate for sequence bias. </p>
<p>subsequent bias? (bidirectional_layer?)</p>
<p><a href="https://towardsdatascience.com/prediction-and-analysis-of-time-series-data-using-tensorflow-2136ef633018" target="_blank" rel="noopener">Sequence bias</a> is when <strong>the order of things can impact the selection of things</strong>. For example, if I were to ask you your favorite TV show, and listed “Game of Thrones”, “Killing Eve”, “Travelers” and “Doctor Who” in that order, you’re probably more likely to select ‘Game of Thrones’ as you are familiar with it, and it’s the first thing you see. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Dataset.shuffle(buffer_size=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>Adjust the learning rate dynamically in time series, sequence and prediction models. </p>
<p>如何动态调整learning rate? <code>callbacks</code></p>
<p>callback如何动态修正 learning rate?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.callbacks.LearningRateScheduler(</span><br><span class="line">    schedule, verbose=<span class="number">0</span></span><br><span class="line">) <span class="comment"># schedule: 可接收(epoch, lr)两个参数的函数</span></span><br><span class="line"></span><br><span class="line">lr_schedule = tf.keras.callbacks.LearningRateScheduler(</span><br><span class="line">    <span class="keyword">lambda</span> epoch: <span class="number">1e-8</span> * <span class="number">10</span>**(epoch / <span class="number">20</span>)) <span class="comment"># callbacks</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义回调，当损失低于阈值时结束训练</span></span><br><span class="line"><span class="comment"># https://www.tensorflow.org/guide/keras/custom_callback</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CusCallback</span><span class="params">(tf.keras.callbacks.Callback)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, patience=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.patience, self.best_weights = patience, <span class="literal">None</span></span><br><span class="line">   	<span class="function"><span class="keyword">def</span> <span class="title">on_train_begin</span><span class="params">(self, logs=None)</span>:</span></span><br><span class="line">        <span class="comment"># the number of epoch it has watied when loss is no longer minimum</span></span><br><span class="line">        self.wait, self.stopped_epoch, self.best = <span class="number">0</span>, <span class="number">0</span>, np.Inf</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span><span class="params">(self, epoch, logs=None)</span>:</span></span><br><span class="line">        current = logs.get(<span class="string">"loss"</span>)</span><br><span class="line">        <span class="comment"># 如果当前loss低于最好loss，则update最好loss</span></span><br><span class="line">        <span class="comment"># 如果当前loss高于最好loss且等待时间(wait)超限，则结束训练</span></span><br><span class="line">        <span class="keyword">if</span> np.less(current, self.best):</span><br><span class="line">            self.best = current</span><br><span class="line">            self.wait = <span class="number">0</span></span><br><span class="line">            self.best_weights = self.model.get_weights()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.wait += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> self.wait &gt;= self.patience:</span><br><span class="line">                self.stopped_epoch = epoch</span><br><span class="line">                self.model.stop_training = <span class="literal">True</span></span><br><span class="line">                print(<span class="string">"Restoring model weights from the end of the best epoch"</span>)</span><br><span class="line">                self.model.set_weights(self.best_weights)</span><br></pre></td></tr></table></figure>







</li>
</ul>
<h1 id="notes"><a href="#notes" class="headerlink" title="notes"></a>notes</h1><ul>
<li>如何寻找合适的learn_rate规模？答：从小到大调整learning_rate以寻找合适的规模。</li>
</ul>
<ol>
<li><strong>将course reviewed一遍，以熟悉内容</strong></li>
<li><strong>熟悉pycharm，在里面写东西</strong></li>
<li><strong>将instruction.pdf里面写image classificatio &amp; word embedding的内容</strong></li>
</ol>
<p>组织结构，管理模式?</p>
<p>各种loss之总结： (y_true, y_pred), y_true is of shape (B, num_class)</p>
<p><code>SparseCategoricalCrossentropy</code>：y_true的形状为 (B, 1)，每个维度为一个整数代表具体哪个类别；y_pred为(B, num_class)</p>
<p>BinaryCrossentropy</p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization" target="_blank" rel="noopener">TextVectorization</a>：文本向量化， keras模型层，支持将一批文本转为一批索引的列表亦或是一批1d array。</p>
<p>调用<code>adapt()</code>方法，以从一个数据集中fit到单词</p>
</li>
</ul>
<ul>
<li><p>序列预测中，如何将series序列数据转换为模型训练可以使用的<code>tf.data.Dataset</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">window_dataset</span><span class="params">(series, window_size, batch_size, shuffle_buffer)</span>:</span></span><br><span class="line">    ds = tf.data.Dataset.from_tensor_slices(series)</span><br><span class="line">    <span class="comment"># 将输入的dataset组合为一个windows的dataset</span></span><br><span class="line">    ds = ds.window(window_size, shift=<span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># map map_func across this dataset and flattens the result</span></span><br><span class="line">    ds = ds.flat_map(<span class="keyword">lambda</span> w: w.batch(window_size))</span><br><span class="line">    </span><br><span class="line">    ds = ds.shuffle(shuffle_buffer)</span><br><span class="line">    ds = ds.map(<span class="keyword">lambda</span> w: (w[:<span class="number">-1</span>], w[<span class="number">1</span>:]))</span><br><span class="line">    <span class="keyword">return</span> ds.batch(batch_size).prefetch(<span class="number">1</span>)   </span><br><span class="line"></span><br><span class="line">ds.batch(batch_size)</span><br><span class="line"><span class="comment"># 将dataset中连续的元素组合为一个tf.data.Dataset</span></span><br><span class="line">dataset = tf.data.Dataset.range(<span class="number">8</span>)</span><br><span class="line">dataset = dataset.batch(<span class="number">3</span>)</span><br><span class="line">list(dataset.as_numpy_iterator())</span><br></pre></td></tr></table></figure>
</li>
<li><p>ImageGenerator</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ImageDataGenerator</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line">train_datagen = ImageGenerator(</span><br><span class="line">    rescale = <span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">20</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>) <span class="comment"># 图像生成时所做的变换	</span></span><br><span class="line"></span><br><span class="line">train_datagen.flow_from_directory(</span><br><span class="line">	dir,</span><br><span class="line">	target_size=(<span class="number">150</span>,<span class="number">150</span>),</span><br><span class="line">	batch_size=<span class="number">10</span>,</span><br><span class="line">	class_mode=<span class="string">'binary'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Takes data &amp; label arrays, generates batches of augmented data.</span></span><br><span class="line">train_datagen.flow(xs, ys=<span class="literal">None</span>, batch_size=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>Tokenizer()</code> 分词器怎么使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.text <span class="keyword">import</span> Tokenizer</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="keyword">import</span> pad_sequences</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(oov_token=<span class="string">'&lt;OOV&gt;'</span>, </span><br><span class="line">                      num_words=<span class="number">1000</span>,</span><br><span class="line">                     lower=<span class="literal">False</span>,<span class="comment">#是否将string转为小写</span></span><br><span class="line">                     char_level=<span class="literal">False</span>,<span class="comment">#是否将每个char视为一个token</span></span><br><span class="line">                     )</span><br><span class="line">tokenizer.fit_on_texts(sentences)</span><br><span class="line">word_index = tokenizer.word_index</span><br><span class="line">print(len(word_index))</span><br><span class="line"></span><br><span class="line">sequences = tokenizer.texts_to_sequences(sentences)</span><br><span class="line">padded = pad_sequences(sequences, padding=<span class="string">'post'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>pad_sequences</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This function transforms a list (of length num_samples) of sequences (lists of integers) into a 2D Numpy array of shape (num_samples, num_timesteps). num_timesteps is either the maxlen argument if provided, or the length of the longest sequence in the list.</span></span><br><span class="line"></span><br><span class="line">pad_sequences(</span><br><span class="line">    sequences, maxlen=<span class="literal">None</span>, dtype=<span class="string">'int32'</span>, padding=<span class="string">'pre'</span>,</span><br><span class="line">    truncating=<span class="string">'pre'</span>, value=<span class="number">0.0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>





</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://github.com/jinlongli2016/2021/07/08/TF_certificate_guide/" data-id="ckqwiervp0000fks37ji1dxpw" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/07/18/frontend-react-refactor/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          React重构案例
        
      </div>
    </a>
  
  
    <a href="/2021/07/02/team%E7%94%9F%E4%BA%A7%E5%8A%9B%E6%A1%86%E6%9E%B6/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Team生产力框架</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%90%88%E4%BD%9C/">合作</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%A2%E9%98%9F%E5%90%88%E4%BD%9C/">团队合作</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%80%9D%E8%80%83/">思考</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%96%B9%E6%B3%95/">方法</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B2%9F%E9%80%9A/">沟通</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%B5%E8%84%91%E6%8A%80%E5%B7%A7/">电脑技巧</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><span class="category-list-count">16</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/opencv/">opencv</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">5</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/tensorflow/">tensorflow</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E6%8A%80%E5%B7%A7%E4%B8%8E%E5%88%86%E6%9E%90/">算法设计技巧与分析</a><span class="category-list-count">8</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B/">编程</a><span class="category-list-count">12</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B/Python/">Python</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B/sql/">sql</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B/%E7%88%AC%E8%99%AB/">爬虫</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%B5%84%E6%BA%90/">资源</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a><span class="archive-list-count">33</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1900/">1900</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSS/" rel="tag">CSS</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RandomThoughts/" rel="tag">RandomThoughts</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scrum/" rel="tag">Scrum</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ab%E6%B5%8B%E8%AF%95/" rel="tag">ab测试</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ast/" rel="tag">ast</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/disc/" rel="tag">disc</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/eda/" rel="tag">eda</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/" rel="tag">git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hardlab/" rel="tag">hardlab</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/javascript/" rel="tag">javascript</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/opencv/" rel="tag">opencv</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/" rel="tag">pandas</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/profiling/" rel="tag">profiling</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rules/" rel="tag">rules</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sift/" rel="tag">sift</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sql/" rel="tag">sql</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/" rel="tag">tensorflow</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E5%BA%93/" rel="tag">个人知识库</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%99%E4%BD%9C/" rel="tag">写作</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%89%8D%E7%AB%AF/" rel="tag">前端</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%A2%E9%98%9F%E5%90%88%E4%BD%9C/" rel="tag">团队合作</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%B0%E9%9A%BE%E6%A0%B7%E6%9C%AC/" rel="tag">困难样本</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag">图像处理</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0/" rel="tag">多任务学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%A6%E4%B9%A0/" rel="tag">学习</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B8%83%E5%8D%A2%E5%A7%86%E5%88%86%E7%B1%BB%E5%AD%A6/" rel="tag">布卢姆分类学</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%80%E5%8F%91%E6%96%B9%E6%B3%95/" rel="tag">开发方法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%80%9D%E7%BB%B4/" rel="tag">思维</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%80%A7%E8%83%BD/" rel="tag">性能</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/" rel="tag">性能调优</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" rel="tag">数据分析</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%B9%E6%B3%95/" rel="tag">方法</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B2%9F%E9%80%9A/" rel="tag">沟通</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/" rel="tag">激活函数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%88%AC%E8%99%AB/" rel="tag">爬虫</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/" rel="tag">科学上网</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E6%8A%80%E5%B7%A7%E4%B8%8E%E5%88%86%E6%9E%90/" rel="tag">算法设计技巧与分析</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%98%E5%9B%BE/" rel="tag">绘图</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BC%96%E7%A8%8B/" rel="tag">编程</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%B0%83%E8%AF%95/" rel="tag">调试</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%87%91%E5%AD%97%E5%A1%94%E5%8E%9F%E7%90%86/" rel="tag">金字塔原理</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 李金龙<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/archives" class="mobile-nav-link">主页</a>
  
    <a href="/categories/Python" class="mobile-nav-link">Python</a>
  
    <a href="/categories/%E7%BC%96%E7%A8%8B" class="mobile-nav-link">编程</a>
  
    <a href="/categories/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E6%8A%80%E5%B7%A7%E4%B8%8E%E5%88%86%E6%9E%90/" class="mobile-nav-link">算法设计</a>
  
    <a href="/archives" class="mobile-nav-link">历史文章</a>
  
    <a href="/about/me" class="mobile-nav-link">个人简历</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>